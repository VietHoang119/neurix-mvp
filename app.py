# app.py
import streamlit as st
import pandas as pd
from backend.embedding import generate_embeddings, build_faiss_index
from backend.query_engine import search_index

st.set_page_config(page_title="Neurix MVP", layout="wide")
st.title("ğŸ§  Neurix Memory Engine â€“ In-Memory MVP")

# 1. Upload & load data
uploaded = st.file_uploader("ğŸ“ Upload CSV / XLSX", type=["csv","xlsx"])
if uploaded and "df" not in st.session_state:
    try:
        st.session_state.df = (
            pd.read_csv(uploaded) if uploaded.name.endswith(".csv")
            else pd.read_excel(uploaded)
        )
    except Exception as e:
        st.error(f"âŒ Lá»—i Ä‘á»c file: {e}")

df = st.session_state.get("df")
if df is not None:
    st.success(f"âœ… Data loaded: {df.shape[0]} rows Ã— {df.shape[1]} cols")
    st.dataframe(df.head(5))

    # 2. Build in-memory FAISS index
    if st.button("ğŸš€ Build Semantic Memory"):
        with st.spinner("ğŸ”„ Äang embed & build index..."):
            embs = generate_embeddings(df, max_rows=500)
            idx = build_faiss_index(embs)
            st.session_state.faiss_idx = idx
        st.success(f"âœ… Index built with {idx.ntotal} vectors")

st.session_state.faiss_idx = idx
st.write("ğŸ”‘ session_state keys:", list(st.session_state.keys()))

# 3. Semantic Query (sáº½ chá»‰ hiá»‡n khi Ä‘Ã£ build xong)
if "faiss_idx" in st.session_state:
    st.subheader("ğŸ’¬ Semantic Query")
    q = st.text_input("Há»i (tiáº¿ng Viá»‡t):")
    if q:
        with st.spinner("ğŸ” Äang tÃ¬mâ€¦"):
            res = search_index(st.session_state.df, st.session_state.faiss_idx, q, top_k=5)
        st.write("Top 5 káº¿t quáº£:")
        st.dataframe(res)
