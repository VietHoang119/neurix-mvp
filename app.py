# app.py
import streamlit as st
import pandas as pd
from backend.embedding import generate_embeddings, build_faiss_index
from backend.query_engine import search_index

st.set_page_config(page_title="Neurix MVP", layout="wide")
st.title("ğŸ§  Neurix Memory Engine - In-Memory MVP")

# 1. Upload & load data
uploaded = st.file_uploader("ğŸ“ Upload CSV/XLSX", type=["csv","xlsx"])
if uploaded and "df" not in st.session_state:
    try:
        st.session_state.df = (
            pd.read_csv(uploaded) if uploaded.name.endswith(".csv")
            else pd.read_excel(uploaded)
        )
    except Exception as e:
        st.error(f"âŒ Lá»—i Ä‘á»c file: {e}")

df = st.session_state.get("df")
if df is not None:
    st.success(f"File Ä‘Ã£ load: {df.shape[0]} rows Ã— {df.shape[1]} cols")
    st.dataframe(df.head(5))

    # 2. Build in-memory FAISS index
    if st.button("ğŸš€ Build Semantic Memory"):
        with st.spinner("Äang embedding & build index..."):
            embs = generate_embeddings(df, max_rows=500)  # cho MVP chá»‰ embed 500 dÃ²ng Ä‘áº§u
            idx = build_faiss_index(embs)
            st.session_state.faiss_idx = idx
            st.success(f"âœ… Táº¡o xong index vá»›i {idx.ntotal} vectors")

# 3. Query
if "faiss_idx" in st.session_state:
    st.subheader("ğŸ’¬ Semantic Query")
    q = st.text_input("Há»i (VN):")
    if q:
        with st.spinner("Äang tÃ¬m káº¿t quáº£..."):
            res = search_index(st.session_state.df, st.session_state.faiss_idx, q, top_k=5)
        st.write("Káº¿t quáº£ top 5:")
        st.dataframe(res)
